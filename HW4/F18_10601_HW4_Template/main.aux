\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\tcolorbox@label[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {paragraph}{Summary}{1}{Doc-Start}}
\@writefile{toc}{\contentsline {paragraph}{Linear Algebra Libraries}{2}{Doc-Start}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Written Questions [20 pts]}{3}{section.1}}
\newlabel{sec:written}{{1}{3}{Written Questions [20 pts]}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Multinomial Logistic Regression [12 pts]}{3}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Empirical Questions [8 pts]}{8}{subsection.1.2}}
\newlabel{sec:empirical}{{1.2}{8}{Empirical Questions [8 pts]}{subsection.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces ``Large Data'' Results\relax }}{9}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{results}{{1.1}{9}{``Large Data'' Results\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Programming [80 pts]}{10}{section.2}}
\newlabel{programming}{{2}{10}{Programming [80 pts]}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The Tasks and Data Sets}{10}{subsection.2.1}}
\newlabel{dataset}{{2.1}{10}{The Tasks and Data Sets}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model Definition}{11}{subsection.2.2}}
\newlabel{modeldescript}{{2.2}{11}{Model Definition}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Implementation}{12}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Programming pipeline for sentiment analyzer based on binary logistic regression\relax }}{12}{figure.caption.2}}
\newlabel{pipeline}{{2.1}{12}{Programming pipeline for sentiment analyzer based on binary logistic regression\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Command Line Arguments}{13}{subsubsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Output: Formatted Data Files}{15}{subsubsection.2.3.2}}
\newlabel{format_output}{{2.3.2}{15}{Output: Formatted Data Files}{subsubsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Output: Labels Files}{15}{subsubsection.2.3.3}}
\newlabel{output}{{2.3.3}{15}{Output: Labels Files}{subsubsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Output Metrics}{15}{subsubsection.2.3.4}}
\newlabel{metrics}{{2.3.4}{15}{Output Metrics}{subsubsection.2.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Feature Engineering}{16}{subsubsection.2.3.5}}
\newlabel{feature}{{2.3.5}{16}{Feature Engineering}{subsubsection.2.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Evaluation}{16}{subsubsection.2.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Autolab Submission}{17}{subsection.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Collaboration Questions}{18}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Implementation Details for Logistic Regression}{19}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Examples of Features}{19}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Efficient Computation of the Dot-Product}{19}{subsection.A.2}}
\newlabel{eq:fastdot}{{A.2}{19}{Efficient Computation of the Dot-Product}{equation.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Data Structures for Fast Dot-Product}{20}{subsection.A.3}}
\@writefile{toc}{\contentsline {paragraph}{Note on out-of-vocabulary features}{20}{subsection.A.3}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Abstract representation of the input file format. The $i$th row of this file will be used to construct the $i$th training example using either Model 1 features (Table \ref  {tab:model1sparse}) or Model 2 features (Table \ref  {tab:model2sparse}).\relax }}{21}{table.caption.3}}
\newlabel{tab:inputfile}{{A.1}{21}{Abstract representation of the input file format. The $i$th row of this file will be used to construct the $i$th training example using either Model 1 features (Table \ref {tab:model1sparse}) or Model 2 features (Table \ref {tab:model2sparse}).\relax }{table.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Dense feature representation for Model 1 corresponding to the input file in Table \ref  {tab:inputfile}. The $i$th row corresponds to the $i$th training example. Each dense feature has the size of the vocabulary in the dictionary. Punctuations are excluded.\relax }}{21}{table.caption.4}}
\newlabel{tab:model1dense}{{A.2}{21}{Dense feature representation for Model 1 corresponding to the input file in Table \ref {tab:inputfile}. The $i$th row corresponds to the $i$th training example. Each dense feature has the size of the vocabulary in the dictionary. Punctuations are excluded.\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Sparse feature representation (bag-of-word representation) for Model 1 corresponding to the input file in Table \ref  {tab:inputfile}.\relax }}{21}{table.caption.5}}
\newlabel{tab:model1sparse}{{A.3}{21}{Sparse feature representation (bag-of-word representation) for Model 1 corresponding to the input file in Table \ref {tab:inputfile}.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Count of word representation for Model 2 corresponding to the input file in Table \ref  {tab:inputfile}. \relax }}{21}{table.caption.6}}
\newlabel{tab:countofword}{{A.4}{21}{Count of word representation for Model 2 corresponding to the input file in Table \ref {tab:inputfile}. \relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Sparse feature representation for Model 2 corresponding to the input file in Table \ref  {tab:inputfile}. Assume that the trimming threshold is 4. As a result, "dog" in example 2 and "apple" in example 3 are removed and the value of all remaining features are reset to value 1.\relax }}{22}{table.caption.7}}
\newlabel{tab:model2sparse}{{A.5}{22}{Sparse feature representation for Model 2 corresponding to the input file in Table \ref {tab:inputfile}. Assume that the trimming threshold is 4. As a result, "dog" in example 2 and "apple" in example 3 are removed and the value of all remaining features are reset to value 1.\relax }{table.caption.7}{}}
\newlabel{LastPage}{{}{22}{}{page.22}{}}
\xdef\lastpage@lastpage{22}
\xdef\lastpage@lastpageHy{22}
